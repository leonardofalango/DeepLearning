{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKooapk2AHQF"
      },
      "source": [
        "#<center> Machine Learning (ML)</center>\n",
        "\n",
        "**Definição:**\n",
        "Machine Learning é um campo da inteligência artificial (IA) que se concentra no desenvolvimento de algoritmos e modelos que permitem aos computadores aprenderem padrões a partir de dados, sem serem explicitamente programados.\n",
        "\n",
        "**Principais Conceitos:**\n",
        "- **Supervisionado:** Algoritmos aprendem a partir de um conjunto de dados rotulado, onde a entrada e saída desejada são conhecidas.\n",
        "- **Não supervisionado:** Algoritmos tentam encontrar padrões em dados não rotulados, sem informações prévias sobre as saídas esperadas.\n",
        "- **Reforço:** Algoritmos aprendem através da interação com um ambiente, recebendo feedback positivo ou negativo.\n",
        "\n",
        "**Aplicações Comuns:**\n",
        "- Classificação e Regressão\n",
        "- Agrupamento\n",
        "- Reconhecimento de Padrões\n",
        "- Processamento de Linguagem Natural (NLP)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mih5YTAYCxDA"
      },
      "source": [
        "\n",
        "#<center> <b> Deep Learning (DL) </b> </center>\n",
        "\n",
        "**Definição:**\n",
        "Deep Learning é uma subárea do Machine Learning que utiliza redes neurais artificiais profundas para modelar e resolver problemas complexos.\n",
        "\n",
        "**Principais Características:**\n",
        "- **Redes Neurais Profundas:** Modelos com múltiplas camadas (profundas) que aprendem representações hierárquicas dos dados.\n",
        "- **Aprendizado de Representações:** Capacidade de aprender automaticamente características e representações relevantes dos dados.\n",
        "\n",
        "**Arquiteturas Notáveis:**\n",
        "- Redes Neurais Convolucionais (CNNs) para visão computacional.\n",
        "- Redes Neurais Recorrentes (RNNs) para processamento sequencial.\n",
        "- Redes Neurais Generativas (GANs) para geração de conteúdo.\n",
        "\n",
        "**Aplicações Comuns:**\n",
        "- Reconhecimento de Imagens e Vídeos\n",
        "- Tradução Automática\n",
        "- Processamento de Voz\n",
        "- Jogos\n",
        "\n",
        "Ambos Machine Learning e Deep Learning têm transformado diversas indústrias, permitindo que sistemas automatizem tarefas complexas e façam previsões precisas com base em dados. O sucesso dessas abordagens depende da qualidade e quantidade dos dados disponíveis, bem como do design e treinamento eficaz dos modelos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip uninstall keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XuhLWLR5xckH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: keras in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (2.15.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
            "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.23.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\disrct\\appdata\\roaming\\python\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Instalando as libs\n",
        "%pip install keras\n",
        "%pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wYLu-i7Ix6Iy"
      },
      "outputs": [],
      "source": [
        "# Importando\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import activations\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import callbacks\n",
        "from keras import preprocessing\n",
        "from keras import initializers\n",
        "from keras import metrics\n",
        "from keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It1x2KKRDF0f"
      },
      "source": [
        "# <center>Criando um modelo sequencial\n",
        "\n",
        "\n",
        "\n",
        "![deep_learning_sequential](https://cdn-images-1.medium.com/max/932/1*eJ36Jpf-DE9q5nKk67xT0Q.jpeg)\n",
        "</center>\n",
        "\n",
        "# Modelo Sequencial\n",
        "\n",
        "Um modelo sequencial é um tipo de modelo em aprendizado de máquina que processa dados em uma ordem específica, elemento por elemento. É especialmente adequado para lidar com dados que têm uma estrutura sequencial, como séries temporais, texto ou áudio.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mJKJhYxeFXzu"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'keras.src.backend' has no attribute 'floatx'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\disrct\\Desktop\\LeonardoFalango\\keras\\dogsAndCats\\deep_learning.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/LeonardoFalango/keras/dogsAndCats/deep_learning.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mSequential()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/LeonardoFalango/keras/dogsAndCats/deep_learning.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m isRgb \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/disrct/Desktop/LeonardoFalango/keras/dogsAndCats/deep_learning.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m inputWidth \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\mixed_precision\\policy.py:360\u001b[0m, in \u001b[0;36mglobal_policy\u001b[1;34m()\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m _global_policy \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[39mif\u001b[39;00m base_layer_utils\u001b[39m.\u001b[39mv2_dtype_behavior_enabled():\n\u001b[1;32m--> 360\u001b[0m         \u001b[39mreturn\u001b[39;00m Policy(backend\u001b[39m.\u001b[39;49mfloatx())\n\u001b[0;32m    361\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m         \u001b[39mreturn\u001b[39;00m Policy(\u001b[39m\"\u001b[39m\u001b[39m_infer\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'keras.src.backend' has no attribute 'floatx'"
          ]
        }
      ],
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "isRgb = True\n",
        "inputWidth = 64\n",
        "inputheight = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1NvnMr4EVwX"
      },
      "source": [
        "# Convolutional Neural Networks (CNNs)\n",
        "\n",
        "**Definição:**\n",
        "Convolutional Neural Networks (CNNs) são uma classe especializada de redes neurais projetadas para processar dados com estrutura de grade, como imagens.\n",
        "\n",
        "**Principais Componentes:**\n",
        "- **Convoluções:** Operações que aplicam filtros sobre a entrada para extrair características locais.\n",
        "- **Camadas de Pooling:** Reduzem a dimensionalidade da representação, preservando características essenciais.\n",
        "- **Camadas Totalmente Conectadas:** Neurônios conectados a todos os neurônios nas camadas adjacentes, usados para a classificação final.\n",
        "\n",
        "**Características Importantes:**\n",
        "- **Invariância a Translação:** CNNs são capazes de reconhecer padrões independentemente da sua posição na imagem.\n",
        "- **Aprendizado de Hierarquia de Recursos:** Camadas convolucionais aprendem características simples nas primeiras camadas e características mais complexas em camadas mais profundas.\n",
        "\n",
        "**Aplicações Comuns:**\n",
        "- **Visão Computacional:** Reconhecimento de objetos, segmentação de imagens.\n",
        "- **Processamento de Imagens Médicas:** Diagnóstico por imagem, detecção de doenças.\n",
        "- **Reconhecimento de Padrões em Sequências:** Análise de séries temporais.\n",
        "\n",
        "**Exemplo de Arquitetura Típica:**\n",
        "```plaintext\n",
        "Entrada -> Convolução -> Ativação -> Pooling -> Convolução -> Ativação -> Pooling -> Totalmente Conectada -> Saída\n",
        "```\n",
        "\n",
        "\n",
        "![convolutional_network](https://miro.medium.com/v2/resize:fit:1400/1*uAeANQIOQPqWZnnuH-VEyw.jpeg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "66ubai3vyLSx"
      },
      "outputs": [],
      "source": [
        "input_shape = (inputWidth, inputheight, 3 if isRgb else 1)\n",
        "\n",
        "# Convolution\n",
        "model.add(\n",
        "  layers.Conv2D(\n",
        "    32,\n",
        "    (5, 5), # Perde 4 pixels de borda\n",
        "    input_shape=input_shape,\n",
        "    activation='relu')\n",
        ")\n",
        "\n",
        "# Pooling\n",
        "model.add(\n",
        "    layers.MaxPooling2D(\n",
        "        pool_size=(2, 2)\n",
        "      )\n",
        ")\n",
        "\n",
        "# Convolution\n",
        "model.add(\n",
        "  layers.Conv2D(\n",
        "    12,\n",
        "    (5, 5),\n",
        "    input_shape=(30, 30, 3),\n",
        "    activation='relu')\n",
        ")\n",
        "\n",
        "# Pooling\n",
        "model.add(\n",
        "    layers.MaxPooling2D(\n",
        "        pool_size=(2, 2)\n",
        "      )\n",
        ")\n",
        "\n",
        "# Convolution\n",
        "model.add(\n",
        "    layers.Conv2D(\n",
        "        12,\n",
        "        (5, 5),\n",
        "        input_shape=(13, 13, 3),\n",
        "        activation='relu'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Pooling\n",
        "model.add(\n",
        "    layers.MaxPooling2D(\n",
        "        pool_size=(2, 2)\n",
        "      )\n",
        ")\n",
        "\n",
        "# Final:\n",
        "# Muitas imagens 5x5\n",
        "# mais precisamente a multiplicacao das convulocoes e filtros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlKE8dwkGOQV"
      },
      "source": [
        "reduz a dimensao para"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6WQSQ4gTGJzO"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    layers.Flatten()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAyew3WX4Pop"
      },
      "source": [
        "# Regularizadores em Modelos de Aprendizado de Máquina\n",
        "\n",
        "Os regularizadores são técnicas usadas para evitar o overfitting em modelos de aprendizado de máquina. Dois tipos comuns são L1 (Lasso) e L2 (Ridge).\n",
        "<hr />\n",
        "\n",
        "## L1 Regularização (Lasso)\n",
        "\n",
        "A L1 regularização adiciona a soma absoluta dos valores dos pesos ao termo de perda durante o treinamento do modelo. Isso ajuda a promover a esparsidade nos pesos, forçando alguns deles a se tornarem exatamente zero.\n",
        "\n",
        "Fórmula L1: <br />\n",
        "\n",
        "$ R(W) = \\lambda \\sum_{i=1}^{n} |w_i| $\n",
        "<hr />\n",
        "\n",
        "## L2 Regularização (Ridge)\n",
        "\n",
        "A L2 regularização adiciona a soma dos quadrados dos valores dos pesos ao termo de perda. Isso penaliza pesos grandes, desencorajando a complexidade excessiva do modelo.\n",
        "\n",
        "Fórmula L2:<br />\n",
        "$R(W) = \\lambda \\sum_{i=1}^{n} w_i^2 $\n",
        "\n",
        "Onde:\n",
        "- $ R(W) $ é a função de regularização.\n",
        "- $ \\lambda $ é o parâmetro de regularização.\n",
        "- $ n $ é o número de pesos no modelo.\n",
        "\n",
        "Em ambas as fórmulas, $ \\lambda $ controla a força da regularização, com valores maiores resultando em penalidades mais fortes nos pesos.\n",
        "\n",
        "Esses reguladores são frequentemente usados em conjunto com a função de perda original durante o treinamento para melhorar a generalização do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0Qlt1rbD4Otb"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    layers.Dense(\n",
        "        64,\n",
        "        kernel_regularizer = regularizers.L2(0.01), # Evitar que os pesos explodam\n",
        "        # kernel_regularizers=regularizers.L2(1e-4)\n",
        "        kernel_initializer = initializers.RandomNormal(stddev=1),\n",
        "        bias_initializer = initializers.Zeros()\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxCVq5YH-asU"
      },
      "source": [
        "# Camada de Dropout\n",
        "\n",
        "A camada de Dropout é uma técnica de regularização usada em redes neurais para evitar o overfitting durante o treinamento do modelo. O Dropout funciona desativando aleatoriamente um percentual de neurônios durante cada passagem de treinamento.\n",
        "\n",
        "## Funcionamento\n",
        "\n",
        "Durante o treinamento, a camada de Dropout \"desliga\" (anula) alguns neurônios aleatórios, impedindo que eles contribuam para a propagação para frente e a retropropagação. Isso força o modelo a aprender representações mais robustas e reduz a dependência excessiva de neurônios específicos.\n",
        "\n",
        "## Fórmula Conceitual\n",
        "\n",
        "A fórmula conceitual do Dropout pode ser expressa da seguinte forma:\n",
        "\n",
        " * $ \\text{Saída da Camada} = \\text{Entrada da Camada} \\times \\text{Máscara de Dropout} $\n",
        "\n",
        "Onde a \"Máscara de Dropout\" é uma matriz binária que zera aleatoriamente alguns elementos.\n",
        "\n",
        "## Parâmetro p\n",
        "\n",
        "O parâmetro \\( p \\) representa a fração de neurônios que serão desligados durante cada atualização. Por exemplo, se \\( p = 0.5 \\), metade dos neurônios será desligada.\n",
        "\n",
        "## Benefícios\n",
        "\n",
        "- **Regularização:** Ajuda a prevenir o overfitting, melhorando a generalização do modelo.\n",
        "- **Redução de Dependência:** Força a rede a aprender representações mais robustas, distribuindo a aprendizagem entre diferentes neurônios.\n",
        "\n",
        "\n",
        "![jooj](https://miro.medium.com/v2/resize:fit:518/0*EY8R7nS10y5kQzOx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FcmadL8J6-CJ"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    layers.Dropout(0.2)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ73oyHYAUzr"
      },
      "source": [
        "\n",
        "# Função de Ativação\n",
        "\n",
        "Uma função de ativação é um componente crucial em uma rede neural. Ela introduz não-linearidades na saída de um neurônio, permitindo que a rede aprenda padrões complexos e relações não lineares nos dados.\n",
        "\n",
        "## Funcionamento\n",
        "\n",
        "- **Linearidade:** Se não houvesse função de ativação (ou se fosse uma função linear), mesmo uma rede profunda seria equivalente a uma única camada, pois a composição de funções lineares é linear.\n",
        "- **Introdução de Não-linearidade:** Funções de ativação introduzem não-linearidade, permitindo que a rede aprenda relações complexas e representações não lineares dos dados.\n",
        "\n",
        "## Algumas Funções de Ativação em LaTeX\n",
        "\n",
        "### Função Sigmóide\n",
        "$ f(x) = \\frac{1}{1 + e^{-x}} $\n",
        "\n",
        "### Tangente Hiperbólica (tanh)\n",
        "$ f(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} $\n",
        "\n",
        "### ReLU (Rectified Linear Unit)\n",
        "$ f(x) = \\max(0, x) $\n",
        "\n",
        "### Leaky ReLU\n",
        "$ f(x) = \\begin{cases} x, & \\text{se } x > 0 \\\\ \\alpha \\cdot x, & \\text{se } x \\leq 0 \\end{cases} $\n",
        "\n",
        "### Softmax\n",
        "$ f(x)_i = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}} $\n",
        "\n",
        "\n",
        "![Conteudo](https://1394217531-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-LvBP1svpACTB1R1x_U4%2F-LvNWUoWieQqaGmU_gl9%2F-LvO3qs2RImYjpBE8vln%2Factivation-functions3.jpg?alt=media&token=f96a3007-5888-43c3-a256-2dafadd5df7c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JtJklF277Eoo"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    layers.Activation(\n",
        "        activations.relu\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5usWapP5QGXb"
      },
      "source": [
        "# Adicionando mais camadas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "20P8r6gxOaT6"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    layers.Dense(\n",
        "        256,\n",
        "        kernel_regularizer = regularizers.L2(0.01),\n",
        "        kernel_initializer = initializers.RandomNormal(stddev=1),\n",
        "        bias_initializer = initializers.Zeros()\n",
        "    )\n",
        ")\n",
        "model.add(layers.Activation(activations.softmax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0nGX1dUrQJ-b"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    layers.Dense(\n",
        "        128,\n",
        "        kernel_regularizer = regularizers.L2(0.01),\n",
        "        kernel_initializer = initializers.RandomNormal(stddev=1),\n",
        "        bias_initializer = initializers.Zeros()\n",
        "    )\n",
        ")\n",
        "model.add(layers.Activation(activations.elu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sp3qUWf2QOgT"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    layers.Dense(\n",
        "        64,\n",
        "        kernel_regularizer = regularizers.L1(0.01),\n",
        "        kernel_initializer = initializers.RandomNormal(stddev=1),\n",
        "        bias_initializer = initializers.Zeros()\n",
        "    )\n",
        ")\n",
        "model.add(layers.Activation(activations.sigmoid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XUKGDBxYQUAT"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    layers.Dense(\n",
        "        32,\n",
        "        kernel_regularizer = regularizers.L1(0.01),\n",
        "        kernel_initializer = initializers.RandomNormal(stddev=1),\n",
        "        bias_initializer = initializers.Zeros()\n",
        "    )\n",
        ")\n",
        "model.add(layers.Activation(activations.tanh))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HgKpFrFQZ-7"
      },
      "source": [
        "A última camada, possui o tamanho da quantidade de classes que você esta tentando classificar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1Nap-_qQQg3J"
      },
      "outputs": [],
      "source": [
        "# Last layer\n",
        "model.add(\n",
        "    layers.Dense(\n",
        "        2,\n",
        "        kernel_regularizer = regularizers.L2(0.01),\n",
        "        kernel_initializer = initializers.RandomNormal(stddev=1),\n",
        "        bias_initializer = initializers.Zeros()\n",
        "    )\n",
        ")\n",
        "model.add(layers.Activation(activations.softmax))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v81lTF0DROnv"
      },
      "source": [
        "# Otimizador em Redes Neurais\n",
        "\n",
        "Um otimizador é um componente vital em treinamento de redes neurais, responsável por ajustar os pesos do modelo com o objetivo de minimizar a função de perda durante o treinamento.\n",
        "\n",
        "## Funcionamento\n",
        "\n",
        "- **Minimização da Função de Perda:** O objetivo do otimizador é encontrar os valores dos pesos que minimizam a função de perda, permitindo que o modelo faça previsões mais precisas.\n",
        "- **Gradiente Descendente:** Muitos otimizadores utilizam o gradiente descendente para iterativamente ajustar os pesos na direção que reduz a perda.\n",
        "\n",
        "<br />\n",
        "<hr />\n",
        "\n",
        "### Gradiente Descendente Estocástico (SGD)<br />\n",
        "$ W_{t+1} = W_t - \\eta \\nabla L(W_t) $ <br />\n",
        "<br />\n",
        "onde $ W_t $ são os pesos, $ \\eta $ é a taxa de aprendizado, e $ \\nabla L(W_t) $ é o gradiente da função de perda.\n",
        "\n",
        "<hr />\n",
        "\n",
        "### Adam (Adaptive Moment Estimation)\n",
        "<br />\n",
        "$ m_{t+1} = \\beta_1 \\cdot m_t + (1 - \\beta_1) \\cdot \\nabla L(W_t) $<br />\n",
        "$ v_{t+1} = \\beta_2 \\cdot v_t + (1 - \\beta_2) \\cdot (\\nabla L(W_t))^2 $<br />\n",
        "$ W_{t+1} = W_t - \\frac{\\eta}{\\sqrt{v_{t+1}} + \\epsilon} \\cdot m_{t+1} $<br />\n",
        "<br />\n",
        "onde $ m_t $ e $ v_t $ são momentos, $ \\beta_1 $ e $ \\beta_2 $ são fatores de decaimento, $ \\eta $ é a taxa de aprendizado, e $ \\epsilon $ é um termo de suavização para evitar divisão por zero.\n",
        "\n",
        "<hr />\n",
        "\n",
        "### RMSprop (Root Mean Square Propagation)\n",
        "<br />\n",
        "$ v_{t+1} = \\beta \\cdot v_t + (1 - \\beta) \\cdot (\\nabla L(W_t))^2 $ <br />\n",
        "$ W_{t+1} = W_t - \\frac{\\eta}{\\sqrt{v_{t+1}} + \\epsilon} \\cdot \\nabla L(W_t) $ <br />\n",
        "<br />\n",
        "onde $ v_t $ é a média ponderada dos quadrados dos gradientes e $ \\beta $ é um fator de decaimento.\n",
        "\n",
        "Esses são apenas alguns dos otimizadores disponíveis, cada um com suas características e aplicabilidades específicas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy8TpuGMS3Dj"
      },
      "source": [
        "# Função de Perda em Aprendizado de Máquina\n",
        "\n",
        "Uma função de perda, também conhecida como função objetivo ou função de custo, quantifica quão bem o modelo está performando em relação aos dados de treinamento. O objetivo é minimizar essa função para que o modelo faça previsões mais precisas.\n",
        "\n",
        "## Funcionamento\n",
        "\n",
        "- **Avaliação do Desempenho:** A função de perda compara as previsões do modelo com os rótulos reais dos dados de treinamento.\n",
        "- **Quantificação do Erro:** A perda atribui um valor numérico que representa o quão distantes são as previsões do modelo em relação aos rótulos reais.\n",
        "- **Otimização:** Durante o treinamento, o modelo ajusta seus parâmetros para minimizar essa função de perda, melhorando assim suas previsões.\n",
        "\n",
        "<hr />\n",
        "<br />\n",
        "\n",
        "### Erro Quadrático Médio (MSE)\n",
        "$ L(y, \\hat{y}) = \\frac{1}{2} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $ <br />\n",
        "<br />\n",
        "onde \\(y\\) são os rótulos reais, \\(\\hat{y}\\) são as previsões do modelo e \\(n\\) é o número de amostras.\n",
        "<br />\n",
        "\n",
        "<br />\n",
        "<hr />\n",
        "<br />\n",
        "\n",
        "### Entropia Cruzada Binária\n",
        "<br />\n",
        "$ L(y, \\hat{y}) = - \\sum_{i=1}^{n} [y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)] $ <br />\n",
        "<br />\n",
        "para tarefas de classificação binária, onde \\(y\\) é o rótulo real e \\(\\hat{y}\\) é a probabilidade prevista.\n",
        "<br />\n",
        "<br />\n",
        "\n",
        "<hr />\n",
        "<br />\n",
        "\n",
        "### Entropia Cruzada Categórica\n",
        "<br />\n",
        "$ L(y, \\hat{y}) = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i) $ <br />\n",
        "<br />\n",
        "para tarefas de classificação multiclasse, onde \\(y\\) é o vetor one-hot dos rótulos reais e \\(\\hat{y}\\) é o vetor de probabilidades previstas.\n",
        "\n",
        "Essas são algumas das funções de perda comumente utilizadas, cada uma adequada para diferentes tipos de tarefas e contextos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "lyBY-jWPRFw7"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=optimizers.Adam(), # adam e svg\n",
        "    loss = losses.BinaryCrossentropy(), # loss function, função de calcular o erro\n",
        "    metrics = [ metrics.Accuracy() ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX-Bo7kbUdkz"
      },
      "source": [
        "# ImageDataGenerator em Aprendizado Profundo\n",
        "\n",
        "`ImageDataGenerator` é uma classe em bibliotecas como Keras que facilita a pré-processamento de imagens durante o treinamento de modelos de aprendizado profundo. Essa ferramenta é frequentemente usada para aumentar o conjunto de dados, melhorando a generalização do modelo.\n",
        "\n",
        "## Parâmetros do ImageDataGenerator\n",
        "\n",
        "Ao criar uma instância de `ImageDataGenerator`, você pode especificar vários parâmetros para controlar as transformações aplicadas às imagens. Aqui estão alguns dos parâmetros utilizados no exemplo:\n",
        "\n",
        "### `rescale`\n",
        "- **Descrição:** Fator de escala para normalizar os valores dos pixels das imagens.\n",
        "- **Exemplo:** `rescale=1.0/255` divide todos os valores de pixel por 255, colocando-os na faixa [0, 1].\n",
        "\n",
        "### `shear_range`\n",
        "- **Descrição:** Intervalo para aplicar cisalhamento aleatório às imagens.\n",
        "- **Exemplo:** `shear_range=0.2` permite um cisalhamento máximo de 20%.\n",
        "\n",
        "### `zoom_range`\n",
        "- **Descrição:** Intervalo para aplicar zoom aleatório às imagens.\n",
        "- **Exemplo:** `zoom_range=0.2` permite um zoom máximo de 20%.\n",
        "\n",
        "### `horizontal_flip`\n",
        "- **Descrição:** Booleano indicando se deve aplicar viragem horizontal aleatória às imagens.\n",
        "- **Exemplo:** `horizontal_flip=True` permite viragem horizontal aleatória.\n",
        "\n",
        "### `vertical_flip`\n",
        "- **Descrição:** Booleano indicando se deve aplicar viragem vertical aleatória às imagens.\n",
        "- **Exemplo:** `vertical_flip=False` impede viragem vertical aleatória.\n",
        "\n",
        "### `validation_split`\n",
        "- **Descrição:** Fração dos dados a serem reservados para validação.\n",
        "- **Exemplo:** `validation_split=0.2` reserva 20% dos dados para validação.\n",
        "\n",
        "## Exemplo Completo\n",
        "```python\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "dataGen = image.ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    validation_split=0.2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0jZDCRYUUeAq"
      },
      "outputs": [],
      "source": [
        "dataGen = image.ImageDataGenerator(\n",
        "    rescale = 1.0 / 255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = False,\n",
        "    validation_split = 0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nKGQCo9U-LS"
      },
      "outputs": [],
      "source": [
        "path = 'lelele'\n",
        "\n",
        "X_train = dataGen.flow_from_directory(\n",
        "    path,\n",
        "    target_size = (64, 64), # resize\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training'\n",
        ")\n",
        "X_test = dataGen.flow_from_directory(\n",
        "    path,\n",
        "    target_size = (64, 64),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_YJVDaTZgOG"
      },
      "source": [
        "# Treinamento de Modelos de Aprendizado de Máquina\n",
        "\n",
        "O treinamento de modelos de aprendizado de máquina é um processo iterativo que envolve os seguintes passos principais:\n",
        "\n",
        "## 1. Escolha do Modelo\n",
        "Escolha a arquitetura do modelo, incluindo o tipo de camadas e a configuração.\n",
        "\n",
        "## 2. Preparação dos Dados\n",
        "Organize os dados de treinamento e validação. Isso inclui divisão em conjuntos, pré-processamento e normalização.\n",
        "\n",
        "## 3. Definição da Função de Perda\n",
        "Escolha uma função de perda que quantifique quão bem o modelo está performando em comparação com os rótulos reais.\n",
        "\n",
        "## 4. Configuração do Otimizador\n",
        "Escolha um otimizador para ajustar os pesos do modelo, minimizando a função de perda. O otimizador utiliza o gradiente descendente para encontrar os pesos ideais.\n",
        "\n",
        "## 5. Treinamento Iterativo\n",
        "Iterativamente, alimente o modelo com lotes de dados de treinamento, calcule a perda, atualize os pesos usando o otimizador e repita o processo.\n",
        "\n",
        "## 6. Avaliação do Desempenho\n",
        "Após o treinamento, avalie o desempenho do modelo usando dados de validação para verificar a capacidade de generalização.\n",
        "\n",
        "## 7. Ajustes e Otimizações\n",
        "Com base nos resultados da avaliação, ajuste hiperparâmetros, modifique a arquitetura do modelo ou aplique técnicas de regularização para otimizar o desempenho.\n",
        "\n",
        "## 8. Implantação\n",
        "Quando satisfeito com o desempenho, o modelo treinado pode ser implantado para fazer previsões em novos dados.\n",
        "\n",
        "O treinamento visa encontrar os pesos do modelo que melhor representam os padrões nos dados de treinamento, permitindo que o modelo generalize bem para novos dados não vistos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw9SnAtZWUdI"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo\n",
        "model.fit(\n",
        "    X_train,\n",
        "    steps_per_epoch = 1_000, # batch_size + steps_per_epoch = quant_dados\n",
        "    epochs = 50, # Quantidade máxima de epocas\n",
        "    validation_steps = 100, # a cada 100 batch_sizes ele verifica\n",
        "    callbacks = [\n",
        "        callbacks.EarlyStopping(patience = 4), # para o treinamento de o erro não melhorar em 4 épocas\n",
        "        callbacks.ModelCheckpoint(\n",
        "            filepath = 'model.{epoch:02d}-{val_loss:.2f}.h5' # Salvando cada época para poder voltar se crashar\n",
        "        )\n",
        "     ]\n",
        ")\n",
        "\n",
        "model.save('model')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
